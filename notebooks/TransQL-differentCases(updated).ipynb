{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "import MeCab\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "import xlrd\n",
    "import string\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "mecab = MeCab.Tagger(\"-Owakati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of unique words in the vocabulary = 2218\n"
     ]
    }
   ],
   "source": [
    "# Select all words in the data file and compute the vocabulary. \n",
    "# Write the cross-lingual word embeddings for those words to a separate file.\n",
    "# This will speed up loading word embeddings and save memory.\n",
    "\n",
    "data_files = [\"../data/newdata.xlsx\", \"../data/olddata.xlsx\"]\n",
    "#data_files = [\"../data/google_translation.xlsx\"]\n",
    "vocab = set()\n",
    "for fname in data_files:\n",
    "    trans_data = xlrd.open_workbook(fname)\n",
    "    sheet = trans_data.sheet_by_index(0)  \n",
    "    for l in range(1, sheet.nrows):\n",
    "        # tokenise Japanese texts\n",
    "        rows = sheet.row_values(l, 0, sheet.ncols)\n",
    "        token_ja = mecab.parse(rows[0].lower())\n",
    "        vocab = vocab.union(set(token_ja.strip().split()))    \n",
    "        # tokenise English texts\n",
    "        vocab = vocab.union(set(nltk.word_tokenize(rows[1].lower())))\n",
    "\n",
    "stop_words = ['(', ')', '[', ']', '@', '•', '`', '-', '❚❚', '●', '（√',  '×', '。', '＠']\n",
    "add_words = ['I', 'like', 'hate', 'cat', 'cats', 'dog', 'dogs', 'banana', '好き', '嫌い', '猫', '犬', '私']\n",
    "vocab = vocab - set(stop_words)\n",
    "vocab = vocab.union(set(add_words))\n",
    "print(\"No of unique words in the vocabulary = %d\" % len(vocab))\n",
    "\n",
    "# write the vocabulary to a file for debugging purposes\n",
    "with open(\"../data/vocab.txt\", 'w') as vocab_file:\n",
    "    for word in vocab:\n",
    "        vocab_file.write(\"%s\\n\" % word)\n",
    "\n",
    "# Lets select the cross-lingual word embeddings for those words in the vocabulary.\n",
    "cross_in_embeds_fname = \"../data/ja2en.txt\"\n",
    "cross_out_embeds_fname = \"../data/ja2en.sel\"\n",
    "first_line = True\n",
    "\n",
    "with open(cross_in_embeds_fname) as cross_in:\n",
    "    with open(cross_out_embeds_fname, 'w') as cross_out:\n",
    "        for line in cross_in:\n",
    "            if first_line:\n",
    "                dim = int(line.split()[1])\n",
    "                cross_out.write(\"%d %d\\n\" % (len(vocab), dim))\n",
    "                first_line = False\n",
    "            elif line.split()[0].lower() in vocab:\n",
    "                cross_out.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cross-lingual word embeddings.\n",
    "large_embeddings = gensim.models.KeyedVectors.load_word2vec_format('../data/ja2en.txt')\n",
    "small_embeddings = gensim.models.KeyedVectors.load_word2vec_format('../data/ja2en.sel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = large_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    stop_words = ['(', ')', '[', ']', '@', '•', '`', '-', '❚❚', '●', '（√',  '×', '。', '＠']\n",
    "    for ch in stop_words:\n",
    "        s = s.replace(ch, ' ')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def av(source, target):\n",
    "    # remove words that are not in the vocabulary from source and target.\n",
    "    source = list(filter(lambda x: x in embeddings, source))\n",
    "    target = list(filter(lambda x: x in embeddings, target))\n",
    "    similarity_average = []\n",
    "    first = []\n",
    "    second = []\n",
    "    n = len(source)\n",
    "    m = len(target)\n",
    "    for i in range(n):\n",
    "        first.append(embeddings[source[i]])\n",
    "    for j in range(m):\n",
    "        second.append(embeddings[target[j]])\n",
    "    source_average = np.mean(first, axis=0)\n",
    "    target_average = np.mean(second, axis=0) \n",
    "    #similarity_average = scipy.spatial.distance.cosine(source_average, target_average)\n",
    "    similarity_average = np.dot(source_average, target_average)/(np.linalg.norm(source_average)*np.linalg.norm(target_average))\n",
    "    return similarity_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sms(source, target):\n",
    "    source = list(filter(lambda x: x in embeddings, source))\n",
    "    target = list(filter(lambda x: x in embeddings, target))\n",
    "    sim_max = []\n",
    "    \n",
    "    n = len(source)\n",
    "    m = len(target)\n",
    "    \n",
    "    for i in range(n):\n",
    "        temp_max = 0\n",
    "        for j in range(m):\n",
    "            first, second = embeddings[source[i]],  embeddings[target[j]]   \n",
    "            #similarity_temp = scipy.spatial.distance.cosine(first, second)\n",
    "            \n",
    "            similarity_temp = np.dot(first, second)/(np.linalg.norm(first)*(np.linalg.norm(second)))\n",
    "            #print(\"sim_temp\", similarity_temp)\n",
    "            if temp_max < similarity_temp:\n",
    "                temp_max = similarity_temp\n",
    "        sim_max.append(temp_max) \n",
    "    #sim_max = np.array(sim_max)        \n",
    "    #print(\"sim_max\", sim_max)\n",
    "    similarity = np.mean(sim_max, axis=0) \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wmd(source, target):\n",
    "    distance = embeddings.wmdistance(source, target)\n",
    "    return (distance, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mwmd(source, target):\n",
    "    # remove words that are not in the vocabulary from source and target.\n",
    "    source = list(filter(lambda x: x in embeddings, source))\n",
    "    target = list(filter(lambda x: x in embeddings, target))\n",
    "     \n",
    "    n = len(source)\n",
    "    m = len(target)\n",
    "    \n",
    "    # compute distances between words\n",
    "    C = np.zeros((n, m), dtype=float)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            first, second = embeddings[source[i]],  embeddings[target[j]]\n",
    "            \n",
    "            # normalisation\n",
    "            first_norm, second_norm = np.linalg.norm(first, ord=2), np.linalg.norm(second, ord=2)\n",
    "                first = first / first_norm\n",
    "            if second_norm > 0:\n",
    "                second = second / second_norm\n",
    "            \n",
    "            C[i,j] = scipy.spatial.distance.euclidean(first, second)\n",
    "    \n",
    "    # Initialise variables\n",
    "    x = np.zeros(n + n*m, dtype=float)\n",
    "    T = x[n:].reshape(n,m)\n",
    "    y = x[:n]\n",
    "    \n",
    "    c = np.zeros_like(x)\n",
    "    c[:n] = 1.0\n",
    "    \n",
    "    # Inequality constraints\n",
    "    b_ub = np.zeros(n*m, dtype=float)\n",
    "    A_ub = np.zeros((n*m, n + n*m), dtype=float)    \n",
    "    for p in range(n*m):\n",
    "        for q in range(n + n*m):\n",
    "            if p % n == q:\n",
    "                A_ub[p, q % n] = -1.0\n",
    "            if (p // n) + 2 * (p % n) + n == q:\n",
    "                A_ub[p,q] = C[p % n, p // n]    \n",
    "    #print(A_ub)\n",
    "    \n",
    "    # Equality constraints for Eq. 5 (Columns in T must be stochastic)\n",
    "    CA_eq = np.zeros((n, n + n*m), dtype=float)\n",
    "    Cb_eq = np.ones(n, dtype=float)\n",
    "    for p in range(n):\n",
    "        for q in range(n + m*p, n + m + m*p):\n",
    "            CA_eq[p,q] = 1.0\n",
    "            \n",
    "    # Equality constraints for Eq. 4 (Rows in T must be stochastic)\n",
    "    RA_eq = np.zeros((m, n + n*m), dtype=float)\n",
    "    Rb_eq = np.ones(m, dtype=float)\n",
    "    for p in range(m):\n",
    "        for q in range(n, n + n*m):\n",
    "            if p == (q - n) % m:\n",
    "                RA_eq[p,q] = 1.0\n",
    "    \n",
    "    # Double stochasticity\n",
    "    #A_eq = np.concatenate((CA_eq, RA_eq), axis=0)\n",
    "    #b_eq = np.concatenate((Cb_eq, Rb_eq), axis=0)    \n",
    "    \n",
    "    res = scipy.optimize.linprog(c, A_ub, b_ub, CA_eq, Cb_eq, method='interior-point', options={'maxiter':10000})\n",
    "    #res = scipy.optimize.linprog(c, A_ub, b_ub, method='simplex') \n",
    "    status = {0 : \"Optimization terminated successfully\",\n",
    "              1 : \"Iteration limit reached\",\n",
    "              2 : \"Problem appears to be infeasible\",\n",
    "              3 : \"Problem appears to be unbounded\",\n",
    "              4 : \"Serious numerical difficulties encountered\"}\n",
    "    if res.status > 0:\n",
    "        print(\"\\x1b[31m %s \\x1b[0m\" % status[res.status])\n",
    "    \n",
    "    if res.status == 2:\n",
    "        # Infeasible problem. Drop equality constrains and try again.\n",
    "        res = scipy.optimize.linprog(c, A_ub, b_ub, method='interior-point') \n",
    "        distance_y = np.sum(res.x[:n])\n",
    "        distance_TC = C.flatten().dot(res.x[n:])\n",
    "        return (distance_y, 2)        \n",
    "    \n",
    "    if res.status == 0:        \n",
    "        print(\"No of iterations to optimisation = %d\" % res.nit)\n",
    "        # objective is the sum of y_i.\n",
    "        distance_y = np.sum(res.x[:n])\n",
    "        #print(\"sum y = \", distance_y)\n",
    "        distance_TC = C.flatten().dot(res.x[n:])\n",
    "        #print(\"sum TC = %f\" % distance_TC)\n",
    "        return (distance_y, res.status)\n",
    "    else:\n",
    "        return (0, res.status) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of instances = 30\n",
      "[('各部名称。（ブレ軽減）ボタン。カッコ内の用語はアイコンを説明している。', 'Camera part; the “anti-shake” button. The term in parentheses is represented by an icon in the manuals except when it appears in the list of camera parts.', 0.30000000000000004), ('各部名称。メニュー操作時では、設定を決定するときに押す。カッコ内の用語はアイコンを説明している。', 'Camera part. Pressing this button applies a selection. The term in parentheses is represented by an icon in the manuals except when it appears in the list of camera parts.', 0.475), ('各部名称。ボタンを押すと表示中の画像を削除する。カッコ内の用語はアイコンを説明している。', 'Camera part. Pressing this button deletes the current picture. The term in parentheses is represented by an icon in the manuals except when it appears in the list of camera parts.', 0.5375)]\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 11\n",
      "No of iterations to optimisation = 12\n",
      "No of iterations to optimisation = 15\n",
      "No of iterations to optimisation = 16\n",
      "No of iterations to optimisation = 12\n",
      "No of iterations to optimisation = 12\n",
      "No of iterations to optimisation = 15\n",
      "No of iterations to optimisation = 11\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 16\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 15\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 15\n",
      "No of iterations to optimisation = 15\n",
      "No of iterations to optimisation = 15\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 15\n",
      "No of iterations to optimisation = 15\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 9\n",
      "No of iterations to optimisation = 12\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 12\n",
      "No of iterations to optimisation = 11\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 10\n",
      "No of iterations to optimisation = 11\n",
      "No of iterations to optimisation = 8\n",
      "No of iterations to optimisation = 12\n",
      "No of iterations to optimisation = 11\n",
      "No of iterations to optimisation = 15\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 13\n",
      "No of iterations to optimisation = 12\n",
      "No of iterations to optimisation = 14\n",
      "No of iterations to optimisation = 15\n",
      "StoT [1.02173004 1.34533191 1.17766348 1.43996853 0.59323335 0.58852745\n",
      " 0.95771033 1.09510589 1.30072891 1.33682468 1.01889017 1.25134954\n",
      " 1.17595233 1.10751166 1.25896657 1.22135028 0.61042752 0.62143653\n",
      " 0.66026329 0.95762471 0.78233761 1.67469081 1.72315038 2.54339229\n",
      " 0.55890371 1.02995087 1.6189634  2.10826449 1.03924225 1.65221522]\n",
      "Source to target failed cases = 0\n",
      "TtoS [1.91278598 1.44332509 1.63357685 1.36287906 3.24573759 3.21588184\n",
      " 2.01995825 1.76391404 1.48355771 1.42535754 1.91653978 1.5500238\n",
      " 1.6377354  1.74238258 1.52813383 1.58123497 2.8379808  3.04229959\n",
      " 2.67753675 2.00511982 2.46569954 1.16343397 1.12239169 0.74438081\n",
      " 3.32970152 1.71193299 1.18875189 0.9381816  1.8456215  1.20569108]\n",
      "Target to source failed cases = 0\n",
      "original distances [2.93451601 2.788657   2.81124033 2.8028476  3.83897094 3.8044093\n",
      " 2.97766858 2.85901993 2.78428662 2.76218222 2.93542995 2.80137334\n",
      " 2.81368772 2.84989424 2.7871004  2.80258526 3.44840831 3.66373612\n",
      " 3.33780004 2.96274453 3.24803716 2.83812478 2.84554207 3.2877731\n",
      " 3.88860524 2.74188386 2.80771529 3.04644608 2.88486375 2.85790631]\n",
      "(30,)\n",
      "[0.3    0.475  0.5375 0.5625 0.4625 0.3875 0.4125 0.4875 0.5125 0.5875\n",
      " 0.4625 0.5625 0.4375 0.5375 0.4875 0.575  0.475  0.1775 0.45   0.425\n",
      " 0.325  0.2275 0.33   0.45   0.225  0.7625 0.525  0.5375 0.7625 0.725 ]\n",
      "(30,)\n",
      "distances [0.24535513 0.28286446 0.2770569  0.27921519 0.01276404 0.02165196\n",
      " 0.23425794 0.26476982 0.28398836 0.28967276 0.2451201  0.27959431\n",
      " 0.27642752 0.2671166  0.28326476 0.27928265 0.11320175 0.0578277\n",
      " 0.14164595 0.23809583 0.16472952 0.27014325 0.26823581 0.15451096\n",
      " 0.         0.29489272 0.2779634  0.21657101 0.25812378 0.2650562 ]\n",
      "(30,)\n",
      "Spearman Full SpearmanrResult(correlation=0.5961477216725094, pvalue=0.0005081239175316456)\n",
      "Pearson Full (0.5020895158123819, 0.004695935968017318)\n",
      "Sperman Low SpearmanrResult(correlation=0.19856919071775495, pvalue=0.47804507640984906)\n",
      "Sperman High SpearmanrResult(correlation=0.24416871212211202, pvalue=0.38048383826914656)\n",
      "Pearson Low (0.24020348791291835, 0.3885090253486845)\n",
      "Pearson High (0.28643975303089775, 0.3006562722501322)\n",
      "Accuracy =  56.666666666666664\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEZCAYAAABWwhjiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naf8PzlCZlLZQp+cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29e4a78668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We will compute the correlation between human ratings and semantic distances over all instances\n",
    "                     \n",
    "trans_data = xlrd.open_workbook('../data/olddata.xlsx')  #open the Excel spreadsheet as workbook\n",
    "sheet = trans_data.sheet_by_index(0)  \n",
    "instances = []\n",
    "for l in range(1, sheet.nrows):\n",
    "    ## tokenise Japanese texts\n",
    "    rows = sheet.row_values(l, 0, sheet.ncols)\n",
    "    instances.append((rows[0], rows[1], float(rows[2])))\n",
    "    \n",
    "print(\"Total number of instances = %d\" % len(instances))\n",
    "print(instances[:3])\n",
    "\n",
    "## 1000 random integers between 0 and 50\n",
    "human_ratings = []\n",
    "distancesst = []\n",
    "distancests = []\n",
    "bleuScores = []\n",
    "bad_count = 0\n",
    "\n",
    "# Evaluate the code in different configurations for mwmd method\n",
    "for x in instances:\n",
    "    source = list(set(mecab.parse(clean_text(x[0]).lower().strip('\\n')).split()))\n",
    "    target = list(set(nltk.word_tokenize(clean_text(x[1]).lower().strip())))\n",
    "    res = mwmd(source, target)\n",
    "    if res[1] > 0:\n",
    "        bad_count += 1\n",
    "    else:\n",
    "        distancesst.append(res[0])\n",
    "        \n",
    "        # Human ratings\n",
    "        human_ratings.append(x[2])\n",
    "        \n",
    "#         # BLEU scores\n",
    "#         bleuScores.append(x[2])\n",
    "        \n",
    "\n",
    "        \n",
    "    # Combine both source to target and target to source direction\n",
    "    # *************************************************************\n",
    "    target = list(set(mecab.parse(clean_text(x[0]).lower().strip('\\n')).split()))\n",
    "    source = list(set(nltk.word_tokenize(clean_text(x[1]).lower().strip())))\n",
    "    res1 = mwmd(source, target)\n",
    "    if res1[1] > 0:\n",
    "        bad_count += 1\n",
    "    else:\n",
    "        distancests.append(res1[0])\n",
    "        \n",
    "distancesst = np.array(distancesst)\n",
    "print(\"StoT\",distancesst)\n",
    "#print(\"distances\", distances)\n",
    "print(\"Source to target failed cases = %d\" % bad_count)\n",
    "\n",
    "distancests = np.array(distancests)\n",
    "print(\"TtoS\",distancests)\n",
    "print(\"Target to source failed cases = %d\" % bad_count)\n",
    "distances = distancesst + distancests\n",
    "# *************************************************************\n",
    "\n",
    "\n",
    "#distances = np.array(distancesst)   ## comment this line if using MWMD method and considering both directions\n",
    "\n",
    "\"\"\"\n",
    "# for average vector, SMS and TMS mehtods\n",
    "#-----------------------------------------\n",
    "for x in instances:\n",
    "    source = list(set(mecab.parse(clean_text(x[0]).lower().strip('\\n')).split()))\n",
    "    target = list(set(nltk.word_tokenize(clean_text(x[1]).lower().strip())))\n",
    "    res = av(source, target)\n",
    "    distancesst.append(res)\n",
    "    human_ratings.append(x[2])\n",
    "distances = np.array(distancesst)\n",
    "#-----------------------------------------\n",
    "\"\"\"\n",
    "print(\"original distances\", distances)\n",
    "print(distances.shape)\n",
    "\n",
    "\n",
    "## convert distances to similarity and scale to [0,1]\n",
    "human_ratings = np.array(human_ratings)\n",
    "#bleuScores = np.array(bleuScores)\n",
    "\n",
    "#--------------comment this lines----------\n",
    "# human_ratings = 1.0 - (human_ratings / np.max(human_ratings))\n",
    "# human_ratings = human_ratings\n",
    "\n",
    "\n",
    "distances = np.array(distances)\n",
    "distances = 1.0 - (distances / np.max(distances))  # comment this line if using averagevector and sms\n",
    "\n",
    "print(human_ratings)\n",
    "print(human_ratings.shape)\n",
    "#print(bleuScores)\n",
    "# print(bleuScores.shape)\n",
    "print(\"distances\", distances)\n",
    "print(distances.shape)\n",
    "\n",
    "spr = scipy.stats.spearmanr(human_ratings, distances)\n",
    "pearson = scipy.stats.pearsonr(human_ratings, distances)\n",
    "print(\"Spearman Full\", spr)\n",
    "print(\"Pearson Full\", pearson)\n",
    "\n",
    "# Plot linear regression line\n",
    "fit = np.polyfit(human_ratings, distances, 1)\n",
    "fit_fn = np.poly1d(fit) \n",
    "plt.plot(human_ratings, fit_fn(human_ratings), '--k')\n",
    "\n",
    "sortinds = np.argsort(human_ratings)\n",
    "distances = distances[sortinds]\n",
    "human_ratings = human_ratings[sortinds]\n",
    "N = len(sortinds) // 2\n",
    "low_bleu, high_bleu = human_ratings[: N], human_ratings[N:]\n",
    "low_sim, high_sim = distances[:N], distances[N:]\n",
    "print(\"Sperman Low\", scipy.stats.spearmanr(low_bleu, low_sim))\n",
    "print(\"Sperman High\", scipy.stats.spearmanr(high_bleu, high_sim))\n",
    "print(\"Pearson Low\", scipy.stats.pearsonr(low_bleu, low_sim))\n",
    "print(\"Pearson High\", scipy.stats.pearsonr(high_bleu, high_sim))\n",
    "\n",
    "# Compute accuracy. For low_human, predicted value must be less than or equal, \n",
    "# and for high_human predicted value must be greater than or equal to be correct.\n",
    "\n",
    "corrects = 0\n",
    "for (x,y) in zip(low_bleu, low_sim):\n",
    "    if fit_fn(x) >= y:\n",
    "        corrects += 1\n",
    "for (x,y) in zip(high_bleu, high_sim):\n",
    "    if fit_fn(x) <= y:\n",
    "        corrects += 1\n",
    "print(\"Accuracy = \", float(100 * corrects) / float(len(distances)))\n",
    "plt.plot(low_bleu, low_sim, 'b*', high_bleu, high_sim, 'r+')\n",
    "plt.xlabel(\"BLEU Scores\")\n",
    "plt.ylabel(\"Translation Quality\")\n",
    "plt.title(\"Spearman = %f, Pearson = %f\" % (spr[0], pearson[0]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1c3717b8e64a16b82be5d377dfe1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We provide a simple UI for entering source (Japanese) and target (English) texts to compare.\n",
    "\n",
    "def Comparison(Source_Ja, Target_En):\n",
    "    source = list(set(mecab.parse(Source_Ja.lower().strip('\\n')).split()))\n",
    "    target = list(set(nltk.word_tokenize(Target_En.lower().strip())))\n",
    "    print(source, target)\n",
    "    distance = mwmd(source, target)[0]\n",
    "    print(\"Semantic distance = %f\\n\" % distance)\n",
    "\n",
    "interact_manual(Comparison, Source_Ja='私は猫が好きです', Target_En=\"I like cats\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process a dataset, predict similarities and save to a file.\n",
    "trans_data = xlrd.open_workbook('../data/newdata.xlsx')  \n",
    "sheet = trans_data.sheet_by_index(0)  \n",
    "scores = []\n",
    "outputs = []\n",
    "distancesst = []\n",
    "distancests = []\n",
    "for l in range(1, sheet.nrows):\n",
    "    rows = sheet.row_values(l, 0, sheet.ncols)\n",
    "    source = list(set(mecab.parse(clean_text(rows[0]).lower().strip('\\n')).split()))\n",
    "    target = list(set(nltk.word_tokenize(clean_text(rows[1]).lower().strip())))\n",
    "    #res1 = sms(source, target)\n",
    "    #distancesst.append(res1)\n",
    "    res1 = mwmd(source, target)\n",
    "    vals_t = -1 if res1[1] > 0 else res1[0]\n",
    "    distancesst.append(vals_t)\n",
    "    \n",
    "    res2 = mwmd(target, source)\n",
    "    valt_s = -1 if res2[1] > 0 else res2[0]\n",
    "    distancests.append(valt_s)\n",
    "\n",
    "distancesst = np.array(distancesst)\n",
    "distancests = np.array(distancests)\n",
    "print(\"stot\",distancesst)\n",
    "print(\"ttos\",distancests)\n",
    "scores = distancesst + distancests\n",
    "#scores = distancesst\n",
    "\n",
    "\"\"\"\n",
    "    scores.append(val)\n",
    "    print(\"val\", val)\n",
    "    \n",
    "\"\"\"  \n",
    "np.savetxt(\"../data/distances.csv\", scores)\n",
    "#scores = np.array(scores)\n",
    "max_val = np.max(scores)\n",
    "print(\"max val\", max_val)\n",
    "scores = 1.0 - (scores / max_val)\n",
    "\"\"\"\n",
    "avg_val = np.average(scores)\n",
    "scores = (scores * 0.85) / avg_val\n",
    "\"\"\"\n",
    "with open(\"../data/pred-sims-newdata.csv\", \"w\") as out_file:\n",
    "    for val in scores:\n",
    "        #print(val)\n",
    "        out_file.write(\"%f\\n\" % val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "-\tL2 normalised, l1 normalised vs. non-normalised (3 options)\n",
    "-\tY_sum vs TC_sum (2 options)\n",
    "-\tFull vocabulary vs. restricted vocabulary (2 options)\n",
    "-\tRow stochasticity, column stochasticity (2 options)\n",
    "\n",
    "- Do 3 x 2 x 2 x 2 = 24 experiments and produce the correlation plots. Prepare a table summarising the results (Spearman, Pearson for Full, High and Low, and accuracy)\n",
    "24 rows and 7 columns excel sheet!\n",
    "Decide which setting is the best.\n",
    "\n",
    "* Once the answer to this question is known, we will score the newdataset using wmd and the best version of the proposed method and get humans to judge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
