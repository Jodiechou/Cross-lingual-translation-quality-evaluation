{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "import MeCab\n",
    "import nltk\n",
    "import xlrd\n",
    "import string\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "mecab = MeCab.Tagger(\"-Owakati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of unique words in the vocabulary = 2155\n"
     ]
    }
   ],
   "source": [
    "# Select all words in the data file and compute the vocabulary. \n",
    "# Write the cross-lingual word embeddings for those words to a separate file.\n",
    "# This will speed up loading word embeddings and save memory.\n",
    "\n",
    "data_files = [\"../data/olddata.xlsx\", \"../data/newdata.xlsx\"]\n",
    "vocab = set()\n",
    "for fname in data_files:\n",
    "    trans_data = xlrd.open_workbook(fname)\n",
    "    sheet = trans_data.sheet_by_index(0)  \n",
    "    for l in range(1, sheet.nrows):\n",
    "        # tokenise Japanese texts\n",
    "        rows = sheet.row_values(l, 0, sheet.ncols)\n",
    "        token_ja = mecab.parse(rows[0].lower())\n",
    "        vocab = vocab.union(set(token_ja.strip().split()))    \n",
    "        # tokenise English texts\n",
    "        vocab = vocab.union(set(nltk.word_tokenize(rows[1].lower())))\n",
    "\n",
    "stop_words = ['(', ')', '[', ']', '@', '•', '`', '-', '❚❚', '●', '（√',  '×', '。', '＠']\n",
    "add_words = ['I', 'like', 'hate', 'cat', 'cats', 'dog', 'dogs', 'banana', '好き', '嫌い', '猫', '犬', '私']\n",
    "vocab = vocab - set(stop_words)\n",
    "vocab = vocab.union(set(add_words))\n",
    "print(\"No of unique words in the vocabulary = %d\" % len(vocab))\n",
    "\n",
    "# write the vocabulary to a file for debugging purposes\n",
    "with open(\"../data/vocab.txt\", 'w') as vocab_file:\n",
    "    for word in vocab:\n",
    "        vocab_file.write(\"%s\\n\" % word)\n",
    "\n",
    "# Lets select the cross-lingual word embeddings for those words in the vocabulary.\n",
    "cross_in_embeds_fname = \"../data/ja-en.txt\"\n",
    "cross_out_embeds_fname = \"../data/ja-en.sel\"\n",
    "first_line = True\n",
    "\n",
    "with open(cross_in_embeds_fname) as cross_in:\n",
    "    with open(cross_out_embeds_fname, 'w') as cross_out:\n",
    "        for line in cross_in:\n",
    "            if first_line:\n",
    "                dim = int(line.split()[1])\n",
    "                cross_out.write(\"%d %d\\n\" % (len(vocab), dim))\n",
    "                first_line = False\n",
    "            elif line.split()[0].lower() in vocab:\n",
    "                cross_out.write(line)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the cross-lingual word embeddings.\n",
    "#large_embeddings = gensim.models.KeyedVectors.load_word2vec_format('../data/ja-en.txt')\n",
    "small_embeddings = gensim.models.KeyedVectors.load_word2vec_format('../data/ja-en.sel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = small_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    stop_words = ['(', ')', '[', ']', '@', '•', '`', '-', '❚❚', '●', '（√',  '×', '。', '＠']\n",
    "    for ch in stop_words:\n",
    "        s = s.replace(ch, ' ')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wmd(source, target):\n",
    "    distance = embeddings.wmdistance(source, target)\n",
    "    return (distance, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mwmd(source, target):\n",
    "    # remove words that are not in the vocabulary from source and target.\n",
    "    source = list(filter(lambda x: x in embeddings, source))\n",
    "    target = list(filter(lambda x: x in embeddings, target))\n",
    "     \n",
    "    n = len(source)\n",
    "    m = len(target)\n",
    "    \n",
    "    # compute distances between words\n",
    "    C = np.zeros((n, m), dtype=float)\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            first, second = embeddings[source[i]],  embeddings[target[j]]\n",
    "            first_norm, second_norm = np.linalg.norm(first), np.linalg.norm(second)\n",
    "            if first_norm > 0:\n",
    "                first = first / first_norm\n",
    "            if second_norm > 0:\n",
    "                second = second / second_norm            \n",
    "            C[i,j] = scipy.spatial.distance.euclidean(first, second)\n",
    "    \n",
    "    # Initialise variables\n",
    "    x = np.zeros(n + n*m, dtype=float)\n",
    "    T = x[n:].reshape(n,m)\n",
    "    y = x[:n]\n",
    "    \n",
    "    c = np.zeros_like(x)\n",
    "    c[:n] = 1.0\n",
    "    \n",
    "    # Inequality constraints\n",
    "    b_ub = np.zeros(n*m, dtype=float)\n",
    "    A_ub = np.zeros((n*m, n + n*m), dtype=float)    \n",
    "    for p in range(n*m):\n",
    "        for q in range(n + n*m):\n",
    "            if p % n == q:\n",
    "                A_ub[p, q % n] = -1.0\n",
    "            if (p // n) + 2 * (p % n) + n == q:\n",
    "                A_ub[p,q] = C[p % n, p // n]    \n",
    "    #print(A_ub)\n",
    "    \n",
    "    # Equality constraints for Eq. 5 (Columns in T must be stochastic)\n",
    "    CA_eq = np.zeros((n, n + n*m), dtype=float)\n",
    "    Cb_eq = np.ones(n, dtype=float)\n",
    "    for p in range(n):\n",
    "        for q in range(n + m*p, n + m + m*p):\n",
    "            CA_eq[p,q] = 1.0\n",
    "            \n",
    "    # Equality constraints for Eq. 4 (Rows in T must be stochastic)\n",
    "    RA_eq = np.zeros((m, n + n*m), dtype=float)\n",
    "    Rb_eq = np.ones(m, dtype=float)\n",
    "    for p in range(m):\n",
    "        for q in range(n, n + n*m):\n",
    "            if p == (q - n) % m:\n",
    "                RA_eq[p,q] = 1.0\n",
    "    \n",
    "    # Double stochasticity\n",
    "    #A_eq = np.concatenate((CA_eq, RA_eq), axis=0)\n",
    "    #b_eq = np.concatenate((Cb_eq, Rb_eq), axis=0)    \n",
    "    \n",
    "    res = scipy.optimize.linprog(c, A_ub, b_ub, CA_eq, Cb_eq, method='simplex', options={'maxiter':10000})\n",
    "    #res = scipy.optimize.linprog(c, A_ub, b_ub, method='simplex')\n",
    "    status = {0 : \"Optimization terminated successfully\",\n",
    "              1 : \"Iteration limit reached\",\n",
    "              2 : \"Problem appears to be infeasible\",\n",
    "              3 : \"Problem appears to be unbounded\",\n",
    "              4 : \"Serious numerical difficulties encountered\"}\n",
    "    if res.status > 0:\n",
    "        print(\"\\x1b[31m %s \\x1b[0m\" % status[res.status])\n",
    "    \n",
    "    if res.status == 2:\n",
    "        # Infeasible problem. Drop equality constrains and try again.\n",
    "        res = scipy.optimize.linprog(c, A_ub, b_ub, method='simplex') \n",
    "        distance_y = np.sum(res.x[:n])\n",
    "        distance_TC = C.flatten().dot(res.x[n:])\n",
    "        return (distance_y, 2)        \n",
    "    \n",
    "    if res.status == 0:        \n",
    "        print(\"No of iterations to optimisation = %d\" % res.nit)\n",
    "        # objective is the sum of y_i.\n",
    "        distance_y = np.sum(res.x[:n])\n",
    "        #print(\"sum y = %f\" % distance_y)\n",
    "        distance_TC = C.flatten().dot(res.x[n:])\n",
    "        #print(\"sum TC = %f\" % distance_TC)\n",
    "        return (distance_y, res.status)\n",
    "    else:\n",
    "        return (0, res.status)    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of instances = 30\n",
      "No of iterations to optimisation = 218\n",
      "No of iterations to optimisation = 362\n",
      "No of iterations to optimisation = 302\n",
      "No of iterations to optimisation = 438\n",
      "No of iterations to optimisation = 167\n",
      "No of iterations to optimisation = 163\n",
      "No of iterations to optimisation = 298\n",
      "No of iterations to optimisation = 308\n",
      "No of iterations to optimisation = 376\n",
      "No of iterations to optimisation = 349\n",
      "No of iterations to optimisation = 490\n",
      "No of iterations to optimisation = 347\n",
      "No of iterations to optimisation = 378\n",
      "No of iterations to optimisation = 452\n"
     ]
    }
   ],
   "source": [
    "# We will compute the correlation between human ratings and semantic distances over all instances\n",
    "\n",
    "trans_data = xlrd.open_workbook('../data/olddata.xlsx')  #open the Excel spreadsheet as workbook\n",
    "sheet = trans_data.sheet_by_index(0)  \n",
    "instances = []\n",
    "for l in range(1, sheet.nrows):\n",
    "    # tokenise Japanese texts\n",
    "    rows = sheet.row_values(l, 0, sheet.ncols)\n",
    "    instances.append((rows[0], rows[1], float(rows[2])))\n",
    "print(\"Total number of instances = %d\" % len(instances))\n",
    "\n",
    "# 1000 random integers between 0 and 50\n",
    "\n",
    "human_ratings = []\n",
    "distances = []\n",
    "bad_count = 0\n",
    "for x in instances:\n",
    "    source = list(set(mecab.parse(clean_text(x[0]).lower().strip('\\n')).split()))\n",
    "    target = list(set(nltk.word_tokenize(clean_text(x[1]).lower().strip())))\n",
    "    res = mwmd(source, target)\n",
    "    if res[1] > 0:\n",
    "        bad_count += 1\n",
    "    else:\n",
    "        distances.append(res[0])\n",
    "        human_ratings.append(x[2])\n",
    "\n",
    "print(\"Failed cases = %d\" % bad_count)\n",
    "\n",
    "# convert distances to similarity and scale to [0,1]\n",
    "human_ratings = np.array(human_ratings)\n",
    "#human_ratings = 1.0 - (human_ratings / np.max(human_ratings))\n",
    "human_ratings = human_ratings\n",
    "distances = np.array(distances)\n",
    "distances = 1.0 - (distances / np.max(distances))\n",
    "spr = scipy.stats.spearmanr(human_ratings, distances)\n",
    "pearson = scipy.stats.pearsonr(human_ratings, distances)\n",
    "print(\"Spearman Full\", spr)\n",
    "print(\"Pearson Full\", pearson)\n",
    "\n",
    "# Plot linear regression line\n",
    "fit = np.polyfit(human_ratings, distances, 1)\n",
    "fit_fn = np.poly1d(fit) \n",
    "plt.plot(human_ratings, fit_fn(human_ratings), '--k')\n",
    "\n",
    "sortinds = np.argsort(human_ratings)\n",
    "distances = distances[sortinds]\n",
    "human_ratings = human_ratings[sortinds]\n",
    "N = len(sortinds) // 2\n",
    "low_human, high_human = human_ratings[: N], human_ratings[N:]\n",
    "low_sim, high_sim = distances[:N], distances[N:]\n",
    "print(\"Sperman Low\", scipy.stats.spearmanr(low_human, low_sim))\n",
    "print(\"Sperman High\", scipy.stats.spearmanr(high_human, high_sim))\n",
    "print(\"Pearson Low\", scipy.stats.pearsonr(low_human, low_sim))\n",
    "print(\"Pearson High\", scipy.stats.pearsonr(high_human, high_sim))\n",
    "\n",
    "# Compute accuracy. For low_human, predicted value must be less than or equal, \n",
    "# and for high_human predicted value must be greater than or equal to be correct.\n",
    "\n",
    "corrects = 0\n",
    "for (x,y) in zip(low_human, low_sim):\n",
    "    if fit_fn(x) >= y:\n",
    "        corrects += 1\n",
    "for (x,y) in zip(high_human, high_sim):\n",
    "    if fit_fn(x) <= y:\n",
    "        corrects += 1\n",
    "print(\"Accuracy = \", float(100 * corrects) / float(len(distances)))\n",
    "plt.plot(low_human, low_sim, 'b*', high_human, high_sim, 'r+')\n",
    "plt.xlabel(\"Human Ratings\")\n",
    "plt.ylabel(\"Translation Quality\")\n",
    "plt.title(\"Spearman = %f, Pearson = %f\" % (spr[0], pearson[0]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed widget Javascript is the wrong version.\n"
     ]
    }
   ],
   "source": [
    "# We provide a simple UI for entering source (Japanese) and target (English) texts to compare.\n",
    "\n",
    "def Comparison(Source_Ja, Target_En):\n",
    "    source = list(set(mecab.parse(Source_Ja.lower().strip('\\n')).split()))\n",
    "    target = list(set(nltk.word_tokenize(Target_En.lower().strip())))\n",
    "    print(source, target)\n",
    "    distance = mwmd(source, target)[0]\n",
    "    print(\"Semantic distance = %f\\n\" % distance)\n",
    "\n",
    "interact_manual(Comparison, Source_Ja='私は猫が好きです', Target_En=\"I like cats\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process a dataset, predict similarities and save to a file.\n",
    "trans_data = xlrd.open_workbook('../data/newdata.xlsx')  \n",
    "sheet = trans_data.sheet_by_index(0)  \n",
    "scores = []\n",
    "for l in range(1, sheet.nrows):\n",
    "    rows = sheet.row_values(l, 0, sheet.ncols)\n",
    "    source = list(set(mecab.parse(clean_text(rows[0]).lower().strip('\\n')).split()))\n",
    "    target = list(set(nltk.word_tokenize(clean_text(rows[1]).lower().strip())))\n",
    "    #res = mwmd(source, target)\n",
    "    res = wmd(source, target)\n",
    "    val = -1 if res[1] > 0 else res[0]\n",
    "    scores.append(val)\n",
    "\n",
    "scores = np.array(scores)\n",
    "max_val = np.max(scores)\n",
    "print(\"max val\", max_val)\n",
    "scores = 1.0 - (scores / max_val)\n",
    "with open(\"../data/pred-sims.csv\", \"w\") as out_file:\n",
    "    for val in scores:\n",
    "        print(val)\n",
    "        out_file.write(\"%f\\n\" % val)\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "-\tL2 normalised, l1 normalised vs. non-normalised (3 options)\n",
    "-\tY_sum vs TC_sum (2 options)\n",
    "-\tFull vocabulary vs. restricted vocabulary (2 options)\n",
    "-\tRow stochasticity, column stochasticity (2 options)\n",
    "\n",
    "- Do 3 x 2 x 2 x 2 = 24 experiments and produce the correlation plots. Prepare a table summarising the results (Spearman, Pearson for Full, High and Low, and accuracy)\n",
    "24 rows and 7 columns excel sheet!\n",
    "Decide which setting is the best.\n",
    "\n",
    "* Once the answer to this question is known, we will score the newdataset using wmd and the best version of the proposed method and get humans to judge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
